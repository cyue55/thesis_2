global_seed: 0
ha: bsrnn
ha_kw:
  input_channels: 1
  reference_channels: [0, 0]
  fs: 16000
  base_channels: 64
  layers: 6
  causal: False
  subband_right_limits: null
  emb_dim: 20
  aggregate: False
  optimizer: Adam
  optimizer_kw:
    lr: 1.0e-3
  loss: cnrhlc
  loss_kw:
    am_kw_hi:
      fs: 16000
      filterbank: drnl
      filterbank_kw:
        f_max: 7643
        filter_type: fir
      ihc: hwrlp
      adaptation: pcen_leaf
      adaptation_kw:
        n_filters: 31
        alpha: 0.98
        delta: 2.0
        r: 0.5
        smoothing_coef: 0.025
        learnable: True
        learn_smoothing: True
        per_channel_smoothing: True
      integration: none
      modulation: none
    am_kw_nh:
      fs: 16000
      filterbank: drnl
      filterbank_kw:
        f_max: 7643
        filter_type: fir
      ihc: hwrlp
      adaptation: pcen_leaf
      adaptation_kw:
      adaptation_kw:
        n_filters: 31    # 这里填你的filterbank输出channel数量
        alpha: 0.98
        delta: 2.0
        r: 0.5
        smoothing_coef: 0.025
        learnable: True
        learn_smoothing: True
        per_channel_smoothing: True
      integration: none
      modulation: none
    loss: l1
    loss_kw: null
  scheduler: ExponentialLR
  scheduler_kw:
    gamma: 0.99
  grad_clip: 5.0
  stft_kw:
    frame_length: 512
    hop_length: 256
  wav_norm: peak
  audiogram: True
  _labels_include_clean: True
  _labels_include_noisy: True
dataset:
  train: dynamic
  train_kw:
    length: 10000
    fs: 16000
    speech_dataset: remote
    speech_dataset_kw:
      url:
        - data/shards/dns-speech-{:02d}.tar
        - data/shards/libri-{:02d}.tar
        - data/shards/vctk-{:02d}.tar
        - data/shards/ears-{:02d}.tar
        - data/shards/mls-{:02d}.tar
      n_archives: 16
      loop: True
      tensor: False
      resume: True
    noise_dataset: remote
    noise_dataset_kw:
      url:
        - data/shards/dns-noise-{:02d}.tar
        - data/shards/fsd50k-{:02d}.tar
        - data/shards/fma-{:02d}.tar
        - data/shards/wham-{:02d}.tar
      n_archives: 16
      loop: True
      tensor: False
      resume: True
    segment_length: 4.0
    seed: 0
    audiogram: True
  val: dynamic
  val_kw:
    length: 100
    fs: 16000
    speech_dataset: remote
    speech_dataset_kw:
      url:
        - data/shards/dns-speech-{:02d}.tar
        - data/shards/libri-{:02d}.tar
        - data/shards/vctk-{:02d}.tar
        - data/shards/ears-{:02d}.tar
        - data/shards/mls-{:02d}.tar
      n_archives: 16
      loop: True
      tensor: False
      resume: False
    noise_dataset: remote
    noise_dataset_kw:
      url:
        - data/shards/dns-noise-{:02d}.tar
        - data/shards/fsd50k-{:02d}.tar
        - data/shards/fma-{:02d}.tar
        - data/shards/wham-{:02d}.tar
      n_archives: 16
      loop: True
      tensor: False
      resume: False
    segment_length: null
    seed: 1
    audiogram: True
    _zero_audiogram: True
trainer:
  workers: 8
  epochs: 200
  device: cuda
  train_batch_sampler: default
  train_batch_sampler_kw:
    batch_size: 32
    shuffle: False
  val_batch_sampler: default
  val_batch_sampler_kw:
    batch_size: 1
    shuffle: False
  ignore_checkpoint: False
  preload: False
  ddp: False
  rank: 0
  use_wandb: True
  profile: False
  val_metrics:
    pesq:
      fs: 16000
    estoi:
      fs: 16000
    snr: null
  val_period: 10
  use_amp: False
  save_on_epochs: []
  persistent_workers: True
  buffer_size: 8
  batch_mix: True
